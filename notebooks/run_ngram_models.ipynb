{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "692ce30b",
   "metadata": {},
   "source": [
    "# example code for training and inference on ngram models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e26f8b9b",
   "metadata": {},
   "source": [
    "## define imports and constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "e593d897",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# get project root for file paths and add project root to python path so imports work from notebooks folder\n",
    "PROJECT_ROOT = Path(\"..\").resolve()\n",
    "if str(PROJECT_ROOT) not in sys.path:\n",
    "    sys.path.insert(0, str(PROJECT_ROOT))\n",
    "\n",
    "from ngram import *\n",
    "\n",
    "# constants\n",
    "DATA_PATH = str(PROJECT_ROOT / \"data\" / \"allseasons.csv\")  # path where data is located\n",
    "CLUSTERS = 5\n",
    "TIER = \"tier_4\" # which tier to train this run on\n",
    "BOTTOM_THRESHOLD = 58\n",
    "TOP_THRESHOLD = 82"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55f8f421",
   "metadata": {},
   "source": [
    "## load and peek data\n",
    "\n",
    "data is expected to be in format:\n",
    "<pre>\n",
    "[\n",
    "    [0, 1, ...], # list expected to contain 82 entries of 0's or 1's (1's representing wins and 0's losses) \n",
    "    [0, 0, 1, ...],\n",
    "    # can contain as many lists as needed\n",
    "]\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "0e9d2f99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "real tiered sample: {\n",
      "tier_0\n",
      "[[0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1], [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1]]\n",
      "len: 168\n",
      "tier_1\n",
      "[[0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1], [1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0]]\n",
      "len: 212\n",
      "tier_2\n",
      "[[1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1], [0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1]]\n",
      "len: 185\n",
      "tier_3\n",
      "[[1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0], [1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1]]\n",
      "len: 92\n",
      "tier_4\n",
      "[[1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0], [1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0]]\n",
      "len: 29\n",
      "}\n",
      "includes records from 686 teams\n"
     ]
    }
   ],
   "source": [
    "# can look up specific team and season with raw_data\n",
    "real_raw_data = read_data(DATA_PATH)\n",
    "\n",
    "tiered_teams = {\n",
    "    \"tier_0\": [],\n",
    "    \"tier_1\": [],\n",
    "    \"tier_2\": [],\n",
    "    \"tier_3\": [],\n",
    "    \"tier_4\": [],\n",
    "}\n",
    "test_data = {\n",
    "    \"2018\": [],\n",
    "    \"2024\": []\n",
    "}\n",
    "\n",
    "for team_season in real_raw_data:\n",
    "    if \"2018\" in team_season:\n",
    "        test_data[\"2018\"].append(real_raw_data[team_season])\n",
    "        continue\n",
    "    if \"2024\" in team_season:\n",
    "        test_data[\"2024\"].append(real_raw_data[team_season])\n",
    "        continue\n",
    "    data = real_raw_data[team_season]\n",
    "    wins = sum(data)\n",
    "    if wins > 59:\n",
    "        tiered_teams[\"tier_4\"].append(data)\n",
    "    elif wins > 51:\n",
    "        tiered_teams[\"tier_3\"].append(data)\n",
    "    elif wins > 42:\n",
    "        tiered_teams[\"tier_2\"].append(data)\n",
    "    elif wins > 30:\n",
    "        tiered_teams[\"tier_1\"].append(data)\n",
    "    else:\n",
    "        tiered_teams[\"tier_0\"].append(data)\n",
    "\n",
    "total_games = 0\n",
    "print(\"real tiered sample: {\")\n",
    "for tier in tiered_teams:\n",
    "    print(tier)\n",
    "    print(tiered_teams[tier][:2])\n",
    "    print(\"len:\", len(tiered_teams[tier]))\n",
    "    total_games += len(tiered_teams[tier])\n",
    "print(\"}\")\n",
    "\n",
    "print(f\"includes records from {total_games} teams\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cde6a952",
   "metadata": {},
   "source": [
    "## train models using mock data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "54657e75",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing team records: 100%|██████████| 29/29 [00:00<00:00, 120311.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "completed training unigram model\n",
      "unigram model cpts {'initial': {1: 0.7728228859907447, 0: 0.22717711400925536}}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing team records: 100%|██████████| 29/29 [00:00<00:00, 87886.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "completed training bigram model\n",
      "bigram model cpts {'initial': {1: 0.6551724137931034, 0: 0.3448275862068966}, 'transition': {1: {1: 0.777838727372463, 0: 0.22216127262753702}, 0: {1: 0.7619047619047619, 0: 0.23809523809523808}}}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing team records: 100%|██████████| 29/29 [00:00<00:00, 66832.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "completed training trigram model\n",
      "trigram model cpts {'initial': {'<start>': {1: 0.6551724137931034, 0: 0.3448275862068966}, 1: {1: 0.7368421052631579, 0: 0.2631578947368421}, 0: {1: 0.8, 0: 0.2}}, 'transition': {1: {1: {1: 0.7773826458036984, 0: 0.22261735419630158}, 0: {1: 0.7732997481108312, 0: 0.22670025188916876}}, 0: {1: {1: 0.7814070351758794, 0: 0.2185929648241206}, 0: {1: 0.7203389830508474, 0: 0.2796610169491525}}}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "real_data = tiered_teams[TIER]\n",
    "\n",
    "unigram_model = train_unigram(real_data)\n",
    "print(\"unigram model cpts\", unigram_model)\n",
    "print()\n",
    "\n",
    "bigram_model = train_bigram(real_data)\n",
    "print(\"bigram model cpts\", bigram_model)\n",
    "print()\n",
    "\n",
    "trigram_model = train_trigram(real_data)\n",
    "print(\"trigram model cpts\", trigram_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5efbfbd6",
   "metadata": {},
   "source": [
    "## infer and measure performance using models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "f300250a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wrote results to results/cluster_5/ngram_results_tier_4_58_82_2018.txt\n"
     ]
    }
   ],
   "source": [
    "# mock actual season\n",
    "# actual_season = generate_season_data() # random generates season data\n",
    "# get actual season from real data\n",
    "SEASON = \"2018\"\n",
    "TEAMS = [\n",
    "    \"ATL\", \"BOS\", \"BRK\", \"CHI\", \"CHO\", \"CLE\", \"DAL\", \"DEN\", \"DET\", \"GSW\",\n",
    "    \"HOU\", \"IND\", \"LAC\", \"LAL\", \"MEM\", \"MIA\", \"MIL\", \"MIN\", \"NOP\", \"NYK\",\n",
    "    \"OKC\", \"ORL\", \"PHI\", \"PHO\", \"POR\", \"SAC\", \"SAS\", \"TOR\", \"UTA\", \"WAS\"\n",
    "]\n",
    "\n",
    "def run_for_team_season(team, season, f):\n",
    "    actual_season = real_raw_data[team + season]\n",
    "    f.write(f\"{team} {season} actual season {actual_season}\\n\")\n",
    "    f.write(\"\\n\")\n",
    "    # print(f\"{team} {season} actual season\", actual_season)\n",
    "    # print()\n",
    "\n",
    "    def infer_and_eval_model(model_type, model):\n",
    "        if model_type == \"unigram\":\n",
    "            predictions = infer_unigram_season(model)\n",
    "        elif model_type == \"bigram\":\n",
    "            predictions = infer_bigram_season(model)\n",
    "        elif model_type == \"trigram\":\n",
    "            predictions = infer_trigram_season(model)\n",
    "        else:\n",
    "            raise ValueError(\"Invalid model type\")\n",
    "        \n",
    "        f.write(f\"{model_type} predictions {predictions}\\n\")\n",
    "        # print(f\"{model_type} predictions\", predictions)\n",
    "        \n",
    "        accuracy = sequence_accuracy(actual_season, predictions)\n",
    "        f.write(f\"{model_type} model accuracy: {accuracy}\\n\")\n",
    "        f.write(\"\\n\")\n",
    "        # print(f\"{model_type} model accuracy:\", accuracy)\n",
    "        # print()\n",
    "        return accuracy\n",
    "\n",
    "    models = [(\"unigram\", unigram_model), (\"bigram\", bigram_model), (\"trigram\", trigram_model)]\n",
    "    model_stats = {\n",
    "        \"unigram\": {},\n",
    "        \"bigram\": {},\n",
    "        \"trigram\": {}\n",
    "    }\n",
    "    for model_type, model in models:\n",
    "        results = infer_and_eval_model(model_type, model)\n",
    "        model_stats[model_type] = results\n",
    "\n",
    "    return model_stats\n",
    "\n",
    "team_stats = {}\n",
    "file_path = f\"results/cluster_{CLUSTERS}/ngram_results_{TIER}_{BOTTOM_THRESHOLD}_{TOP_THRESHOLD}_{SEASON}.txt\"\n",
    "\n",
    "with open(file_path, \"w\") as f:\n",
    "    for team in TEAMS:\n",
    "        wins = sum(real_raw_data[team + SEASON])\n",
    "        if wins > BOTTOM_THRESHOLD and wins < TOP_THRESHOLD:\n",
    "            team_stats[team] = run_for_team_season(team, SEASON, f)\n",
    "\n",
    "    averages = {\n",
    "        \"unigram\": 0,\n",
    "        \"bigram\": 0,\n",
    "        \"trigram\": 0\n",
    "    }\n",
    "    for team in team_stats:\n",
    "        for model_type in averages.keys():\n",
    "            averages[model_type] += team_stats[team][model_type]\n",
    "\n",
    "    for key in averages.keys():\n",
    "        averages[key] /= len(team_stats)\n",
    "\n",
    "    f.write(\"-\" * 40 + \"\\n\")\n",
    "    f.write(f\"averages: {averages}\")\n",
    "\n",
    "print(f\"wrote results to {file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e59b9538",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
